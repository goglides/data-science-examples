{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"fae53c13defb4f59a6ce7f6b69b98b12":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b52851aa929d449182a986f345841016","IPY_MODEL_463399c20052479d8050ddc89fcc444b","IPY_MODEL_55bdbde990904b6bbfa29e41cfaf1605"],"layout":"IPY_MODEL_2aa346b915c34056a73df3a1bc4ae00f"}},"b52851aa929d449182a986f345841016":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_29e89dff0d6b431f903fd6da24bf6663","placeholder":"​","style":"IPY_MODEL_6d37c12ce6914e6285aa89ca19c871c3","value":"Loading checkpoint shards: 100%"}},"463399c20052479d8050ddc89fcc444b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_678470f82850485e87735013b64ea7e7","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4c0efee15455467192f3016cbedb5778","value":2}},"55bdbde990904b6bbfa29e41cfaf1605":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a6a330c322a44d8b97b1274658f2dea3","placeholder":"​","style":"IPY_MODEL_84dd6ebca0584091a9c57917c862ab96","value":" 2/2 [00:58&lt;00:00, 26.56s/it]"}},"2aa346b915c34056a73df3a1bc4ae00f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29e89dff0d6b431f903fd6da24bf6663":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d37c12ce6914e6285aa89ca19c871c3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"678470f82850485e87735013b64ea7e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c0efee15455467192f3016cbedb5778":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a6a330c322a44d8b97b1274658f2dea3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84dd6ebca0584091a9c57917c862ab96":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb5097e7babb49909edf5448b84d2546":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e58accc68f8d4bd2af6d22e8cc146937","IPY_MODEL_da4dc49821644e26adec3926a8132e78","IPY_MODEL_a1be0037c2f34c0d83e15539f06f7a2c"],"layout":"IPY_MODEL_0cb6ff95b6cd499b860712f5d6a873d0"}},"e58accc68f8d4bd2af6d22e8cc146937":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_90b1de75df0045f3b1838736503a78fa","placeholder":"​","style":"IPY_MODEL_884a6a79294d4009b3411635a175472e","value":"Loading checkpoint shards: 100%"}},"da4dc49821644e26adec3926a8132e78":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9f16302f16b4a02b9b3f5e9d59447a5","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_00a9d77209d540babf78ed5500d4899d","value":2}},"a1be0037c2f34c0d83e15539f06f7a2c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7171ca835f8e4b5dab807df6f034c9c7","placeholder":"​","style":"IPY_MODEL_50b6f85d4c66440498ce5fc9dac49108","value":" 2/2 [00:58&lt;00:00, 26.56s/it]"}},"0cb6ff95b6cd499b860712f5d6a873d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90b1de75df0045f3b1838736503a78fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"884a6a79294d4009b3411635a175472e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e9f16302f16b4a02b9b3f5e9d59447a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"00a9d77209d540babf78ed5500d4899d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7171ca835f8e4b5dab807df6f034c9c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50b6f85d4c66440498ce5fc9dac49108":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["### Prompt Compression using LLMLingua Python library and OpenAI"],"metadata":{"id":"h_Sj5NC06qHX"}},{"cell_type":"code","source":["!pip install -q llmlingua openai accelerate python-dotenv llama-index llama-index-postprocessor-longllmlingua"],"metadata":{"id":"tAr0GZqgy4gu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708111554593,"user_tz":-330,"elapsed":16084,"user":{"displayName":"Mallikarjuna M","userId":"18087916558107570605"}},"outputId":"37551230-817f-45b6-bfda-8d58ad92e31f"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/226.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m631.0/631.0 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.0/284.0 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["#Google drive mount\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","%cd drive/MyDrive/Upwork_Projects/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mq_8ZcLLEWy4","outputId":"c7367a6a-86a7-4116-b97e-3d4f04efb6fd","executionInfo":{"status":"ok","timestamp":1708113522726,"user_tz":-330,"elapsed":3801,"user":{"displayName":"Mallikarjuna M","userId":"18087916558107570605"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n","/content/drive/MyDrive/Upwork_Projects\n"]}]},{"cell_type":"code","source":["#Env variable for openai api key\n","from dotenv import load_dotenv\n","import os\n","import openai\n","load_dotenv()\n","api_key = os.getenv(\"openai_api_key\")\n","openai.api_key = api_key"],"metadata":{"id":"tuosfn0oEX8O","executionInfo":{"status":"ok","timestamp":1708113527280,"user_tz":-330,"elapsed":1200,"user":{"displayName":"Mallikarjuna M","userId":"18087916558107570605"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["#Load pdf documents\n","from llama_index.core import download_loader, VectorStoreIndex\n","PDFReader = download_loader(\"PDFReader\")\n","loader = PDFReader()\n","documents = loader.load_data(file='data/Power of The Subconscious Mind - Joseph Murphy.pdf')\n","print(type(documents))\n","print(len(documents))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pt9OCYcUEYJc","outputId":"e8c4a1a1-ce87-42b3-ae68-c40d387b43f6","executionInfo":{"status":"ok","timestamp":1708113550027,"user_tz":-330,"elapsed":16651,"user":{"displayName":"Mallikarjuna M","userId":"18087916558107570605"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-3-ae2831fa17a4>:2: DeprecationWarning: Call to deprecated function (or staticmethod) download_loader. (`download_loader()` is deprecated. Please install tool using pip install directly instead.)\n","  PDFReader = download_loader(\"PDFReader\")\n"]},{"output_type":"stream","name":"stdout","text":["<class 'list'>\n","222\n"]}]},{"cell_type":"code","source":["#LLama-index vector store\n","index = VectorStoreIndex.from_documents(documents)\n","retriever = index.as_retriever(similarity_top_k=4)"],"metadata":{"id":"3_cU2pQTEYNP","executionInfo":{"status":"ok","timestamp":1708113562616,"user_tz":-330,"elapsed":7937,"user":{"displayName":"Mallikarjuna M","userId":"18087916558107570605"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["#Question and contexts\n","question = \"What is the difference between conscious mind and subconscious mind?\"\n","contexts = retriever.retrieve(question)"],"metadata":{"id":"khfz11qDEzQC","executionInfo":{"status":"ok","timestamp":1708113585276,"user_tz":-330,"elapsed":20825,"user":{"displayName":"Mallikarjuna M","userId":"18087916558107570605"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["context_list = [n.get_content() for n in contexts]\n","context_list[0]"],"metadata":{"id":"VetZ9B26EzXM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Prompt Compressor\n","from llmlingua import PromptCompressor\n","llm_lingua = PromptCompressor(\n","    model_name=\"NousResearch/Llama-2-7b-hf\",  # Default model\n","    device_map=\"cuda\",  # Device environment (e.g., 'cuda', 'cpu', 'mps')\n","    model_config={},  # Configuration for the Huggingface model\n","    open_api_config={},  # Configuration for OpenAI Embedding\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":246,"referenced_widgets":["fae53c13defb4f59a6ce7f6b69b98b12","b52851aa929d449182a986f345841016","463399c20052479d8050ddc89fcc444b","55bdbde990904b6bbfa29e41cfaf1605","2aa346b915c34056a73df3a1bc4ae00f","29e89dff0d6b431f903fd6da24bf6663","6d37c12ce6914e6285aa89ca19c871c3","678470f82850485e87735013b64ea7e7","4c0efee15455467192f3016cbedb5778","a6a330c322a44d8b97b1274658f2dea3","84dd6ebca0584091a9c57917c862ab96"]},"id":"MoEIgpgXybG_","outputId":"d4f37d3a-a2a4-4297-be8f-6ef7322c8fa0","executionInfo":{"status":"ok","timestamp":1708113266111,"user_tz":-330,"elapsed":65090,"user":{"displayName":"Mallikarjuna M","userId":"18087916558107570605"}}},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fae53c13defb4f59a6ce7f6b69b98b12"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["compressed_prompt = llm_lingua.compress_prompt(context_list,\n","                                               instruction=\"Given the context, please answer the question correctly.\",\n","                                               question=question,\n","                                               ratio = 0.7,\n","                                               target_token=-1,\n","                                               rank_method= \"llmlingua\")"],"metadata":{"id":"J7blu3m9yvCm","executionInfo":{"status":"ok","timestamp":1708113281757,"user_tz":-330,"elapsed":5768,"user":{"displayName":"Mallikarjuna M","userId":"18087916558107570605"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["print(compressed_prompt['compressed_prompt'])"],"metadata":{"id":"ckY4r-sJJILH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# The response from original and compressed prompt\n","from llama_index.llms.openai import OpenAI\n","import tiktoken\n","# Combine prompts\n","original_prompt = \"\\n\\n\".join(context_list + [question])\n","compressed_prompt_text = compressed_prompt['compressed_prompt']\n","prompts = [original_prompt, compressed_prompt_text]\n","# Get the encoding object\n","enc = tiktoken.get_encoding(\"cl100k_base\")\n","# Tokenize prompts\n","tokenized_prompts = [(p, len(enc.encode(p))) for p in prompts]\n","# Calculate compressed ratio\n","compressed_ratio = tokenized_prompts[0][1] / (tokenized_prompts[1][1] + 1e-5)\n","# Format output strings\n","token_comp = f\"Original Prompt: {tokenized_prompts[0][1]}\\n\" + \\\n","             f\"Compressed Prompt: {tokenized_prompts[1][1]}\\n\" + \\\n","             f\"Compressed Ratio: {compressed_ratio:.2f}x\"\n","print(token_comp)\n","print(\"\\n\")\n","# Initialize OpenAI model\n","llm = OpenAI(model=\"gpt-3.5-turbo-0125\")\n","# Batch processing of prompts\n","for prompt_text, _ in tokenized_prompts:\n","    response = llm.complete(prompt_text)\n","    print(str(response))\n","    print(\"-\" * 100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o3Uvk87E6-dM","outputId":"0ae4af31-38cb-44c8-ef73-f4b733fd4854","executionInfo":{"status":"ok","timestamp":1708113306409,"user_tz":-330,"elapsed":5615,"user":{"displayName":"Mallikarjuna M","userId":"18087916558107570605"}}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Original Prompt: 1796\n","Compressed Prompt: 532\n","Compressed Ratio: 3.38x\n","\n","\n","The conscious mind is the reasoning mind, which makes decisions and choices based on conscious thought. It is the part of the mind that is aware of the present moment and actively engages in decision-making. On the other hand, the subconscious mind operates below the level of conscious awareness and is responsible for automatic functions such as breathing, digestion, and circulation. It does not reason or argue like the conscious mind, but rather accepts and acts upon the beliefs and suggestions that are impressed upon it. The subconscious mind is like a soil that accepts any kind of seed, whether positive or negative, and brings about corresponding results in the outer experience. The conscious and subconscious minds are not separate entities, but rather two spheres of activity within one mind.\n","----------------------------------------------------------------------------------------------------\n","The conscious mind is the part of the mind that is aware of thoughts, feelings, and perceptions, and is responsible for decision-making and rational thinking. The subconscious mind, on the other hand, operates below the level of conscious awareness and influences behavior, emotions, and beliefs based on past experiences and conditioning. The subconscious mind does not reason or argue, but rather accepts and acts upon the beliefs and thoughts that are planted in it.\n","----------------------------------------------------------------------------------------------------\n"]}]},{"cell_type":"markdown","source":["### Prompt Compression using Llama-Index's longllmlingua"],"metadata":{"id":"VqTFt9MpFfYW"}},{"cell_type":"code","source":["# Import the necessary modules from llama_index\n","# from llama_index.core.query_engine import RetrieverQueryEngine\n","from llama_index.core.response_synthesizers import CompactAndRefine\n","from llama_index.postprocessor.longllmlingua import LongLLMLinguaPostprocessor\n","# Create a postprocessor object using LongLLMLinguaPostprocessor with the specified parameters\n","node_postprocessor = LongLLMLinguaPostprocessor(\n","    instruction_str=\"Given the context, please answer the final question\",\n","    target_token=300,\n","    rank_method=\"longllmlingua\",\n","    additional_compress_kwargs={\n","        \"condition_compare\": True,\n","        \"condition_in_question\": \"after\",\n","        \"context_budget\": \"+100\",\n","        \"reorder_context\": \"sort\",  # enable document reorder,\n","        \"dynamic_context_compression_ratio\": 0.5,\n","    },\n",")\n","# Create a retriever object with the default parameters\n","# The retriever will use the vector store index to fetch the most relevant nodes\n","retrieved_nodes = retriever.retrieve(question)\n","# Create a synthesizer object with the default parameters\n","# The synthesizer will use the compact and refine mode to generate a response\n","synthesizer = CompactAndRefine()"],"metadata":{"id":"q7YIWPjbSVsH","colab":{"base_uri":"https://localhost:8080/","height":246,"referenced_widgets":["fb5097e7babb49909edf5448b84d2546","e58accc68f8d4bd2af6d22e8cc146937","da4dc49821644e26adec3926a8132e78","a1be0037c2f34c0d83e15539f06f7a2c","0cb6ff95b6cd499b860712f5d6a873d0","90b1de75df0045f3b1838736503a78fa","884a6a79294d4009b3411635a175472e","e9f16302f16b4a02b9b3f5e9d59447a5","00a9d77209d540babf78ed5500d4899d","7171ca835f8e4b5dab807df6f034c9c7","50b6f85d4c66440498ce5fc9dac49108"]},"outputId":"10db366e-7ffd-4a05-b50b-f9cde23d7bd3","executionInfo":{"status":"ok","timestamp":1708113665678,"user_tz":-330,"elapsed":65159,"user":{"displayName":"Mallikarjuna M","userId":"18087916558107570605"}}},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb5097e7babb49909edf5448b84d2546"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["from llama_index.core.indices.query.schema import QueryBundle\n","new_retrieved_nodes = node_postprocessor.postprocess_nodes(\n","    retrieved_nodes, query_bundle=QueryBundle(query_str=question)\n",")"],"metadata":{"id":"UMrA--VkSV0U","executionInfo":{"status":"ok","timestamp":1708113679287,"user_tz":-330,"elapsed":6649,"user":{"displayName":"Mallikarjuna M","userId":"18087916558107570605"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["#Count original and compressed tokens\n","original_contexts = \"\\n\\n\".join([n.get_content() for n in retrieved_nodes])\n","compressed_contexts = \"\\n\\n\".join([n.get_content() for n in new_retrieved_nodes])\n","\n","original_tokens = node_postprocessor._llm_lingua.get_token_length(original_contexts)\n","compressed_tokens = node_postprocessor._llm_lingua.get_token_length(compressed_contexts)\n","\n","# print(compressed_contexts)\n","print(\"\\n\")\n","print(\"Original Tokens:\", original_tokens)\n","print(\"Compressed Tokens:\", compressed_tokens)\n","print(\"Comressed Ratio:\", f\"{original_tokens/(compressed_tokens + 1e-5):.2f}x\")"],"metadata":{"id":"ZVFFjfvHSV4R","colab":{"base_uri":"https://localhost:8080/"},"outputId":"42476822-2620-40c6-ede7-1510fb63ea66","executionInfo":{"status":"ok","timestamp":1708113682617,"user_tz":-330,"elapsed":713,"user":{"displayName":"Mallikarjuna M","userId":"18087916558107570605"}}},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","Original Tokens: 2110\n","Compressed Tokens: 83\n","Comressed Ratio: 25.42x\n"]}]},{"cell_type":"code","source":["#llama-index synthesizer for response generation\n","response = synthesizer.synthesize(question, new_retrieved_nodes)"],"metadata":{"id":"g3ZBnhnLF_PJ","executionInfo":{"status":"ok","timestamp":1708113693398,"user_tz":-330,"elapsed":2447,"user":{"displayName":"Mallikarjuna M","userId":"18087916558107570605"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["print(str(response))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9j8reF4vTGtG","outputId":"653b5121-8550-47e8-cd94-fdd23c13f7f7","executionInfo":{"status":"ok","timestamp":1708113699408,"user_tz":-330,"elapsed":474,"user":{"displayName":"Mallikarjuna M","userId":"18087916558107570605"}}},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["The conscious mind and the subconscious mind are two different aspects of our mental processes. The conscious mind is responsible for our awareness and rational thinking. It is the part of our mind that we actively use to make decisions, solve problems, and engage in logical reasoning. On the other hand, the subconscious mind operates below the level of conscious awareness. It is responsible for storing and processing information that we are not actively thinking about. The subconscious mind influences our thoughts, emotions, and behaviors, often without us realizing it. It is also believed to play a role in shaping our beliefs, habits, and automatic responses.\n"]}]}]}
